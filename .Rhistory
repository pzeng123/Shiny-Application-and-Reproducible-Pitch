xlab("Means") +
ylab("Frequency")
ggplot() +
aes(means) +
geom_histogram(bins=50, colour="black", fill="blue") +
geom_vline(xintercept = 5, colour = "red") +
geom_vline(xintercept = 4.994883, colour = "green") +
ggtitle("Distribution of 1000 means of exponential distribution") +
xlab("Means") +
ylab("Frequency")
ggplot() +
aes(means) +
geom_histogram(bins=50, colour="black", fill="blue") +
geom_vline(xintercept = theoretical_mean, colour = "red") +
geom_vline(xintercept = mean(means), colour = "green") +
ggtitle("Distribution of 1000 means of exponential distribution") +
xlab("Means") +
ylab("Frequency")
ggplot() +
aes(means) +
geom_histogram(bins=50, colour="black", fill="blue") +
geom_vline(xintercept = theoretical_mean, colour = "red") +
geom_vline(xintercept = mean(means), colour = "green") +
ggtitle("Distribution of 1000 means of exponential distribution") +
xlab("Means") +
ylab("Density %") +
legend('topright', c("Sample Mean", "Theoretical Mean"))
ggplot() +
aes(means) +
geom_histogram(bins=50, colour="black", fill="blue") +
geom_vline(xintercept = theoretical_mean, colour = "red") +
geom_vline(xintercept = mean(means), colour = "green") +
ggtitle("Distribution of 1000 means of exponential distribution") +
xlab("Means") +
ylab("Density %") +
ggplot() +
aes(means) +
geom_histogram(bins=50, colour="black", fill="blue") +
geom_vline(xintercept = theoretical_mean, colour = "red") +
geom_vline(xintercept = mean(means), colour = "green") +
ggtitle("Distribution of 1000 means of exponential distribution") +
xlab("Means") +
ylab("Density %")
ggplot() +
aes(means) +
geom_histogram(bins=50, colour="black", fill="blue") +
geom_vline(xintercept = theoretical_mean, colour = "red") +
geom_vline(xintercept = mean(means), colour = "green") +
ggtitle("Exponential distribution") +
xlab("Means") +
ylab("Density %")
variance <- var(means)
variance
theoretical_variance <- ((1/lambda)^2)/n
theoretical_variance
```there is a small difference between then, `r sample_variance - theoretical_variance`, to be exact.
theoretical_variance <- ((1/lambda)^2)/n
theoretical_variance
df <- data.frame(means)
ggplot(df,aes(x = means)) +
geom_histogram(aes(y=..density..), bins=50, colour="black",fill="yellow") +
labs(title="Distribution of Means of exponential distribution", y="Frequency") +
stat_function(fun=dnorm,args=list( mean=1/lambda, sd=sqrt(theoretical_variance)), color = "red", size = 1.0) +
stat_function(fun=dnorm,args=list( mean=mean(means), sd=sqrt(variance)), color = "green", size = 1.0)
df <- data.frame(means)
ggplot(df,aes(x = means)) +
geom_histogram(aes(y=..density..), bins=50, colour="black",fill="blue") +
labs(title="Distribution of Means of exponential distribution", y="Frequency") +
stat_function(fun=dnorm,args=list( mean=1/lambda, sd=sqrt(theoretical_variance)), color = "red", size = 1.0) +
stat_function(fun=dnorm,args=list( mean=mean(means), sd=sqrt(variance)), color = "green", size = 1.0)
df <- data.frame(means)
ggplot(df,aes(x = means)) +
geom_histogram(aes(y=..density..), bins=50, colour="black",fill="blue") +
labs(title="Exponential distribution", y="Frequency") +
stat_function(fun=dnorm,args=list( mean=1/lambda, sd=sqrt(theoretical_variance)), color = "red", size = 1.0) +
stat_function(fun=dnorm,args=list( mean=mean(means), sd=sqrt(variance)), color = "green", size = 1.0)
df <- data.frame(means)
ggplot(df,aes(x = means)) +
geom_histogram(aes(y=..density..), bins=50, colour="black",fill="blue") +
labs(title="Exponential distribution", y="Density %") +
stat_function(fun=dnorm,args=list( mean=1/lambda, sd=sqrt(theoretical_variance)), color = "red", size = 1.0) +
stat_function(fun=dnorm,args=list( mean=mean(means), sd=sqrt(variance)), color = "green", size = 1.0)
qqnorm(means, main ="Q-Q Plot")
qqline(means, col = "3")
Sys.getenv("PATH")
ggplot() +
aes(means) +
geom_histogram(bins=50, colour="black", fill="blue") +
geom_vline(xintercept = theoretical_mean, colour = "red") +
geom_vline(xintercept = mean(means), colour = "green") +
ggtitle("Exponential distribution") +
xlab("Means") +
ylab("Density %")
library(ggplot2)
# set parameters
lambda <- 0.2 # lambda for rexp(n, lambda)
n <- 40 # number of exponetials
SimulationsNums <- 1000 # number of Simulations
# set the seed to create reproducability
set.seed(1000)
m <- matrix(rexp(n * SimulationsNums, lambda), SimulationsNums, n)
means <- apply(m, 1, mean)
mean(means)
theoretical_mean <- 1/lambda
theoretical_mean
ggplot() +
aes(means) +
geom_histogram(bins=50, colour="black", fill="blue") +
geom_vline(xintercept = theoretical_mean, colour = "red") +
geom_vline(xintercept = mean(means), colour = "green") +
ggtitle("Exponential distribution") +
xlab("Means") +
ylab("Density %")
variance <- var(means)
variance
theoretical_variance <- ((1/lambda)^2)/n
theoretical_variance
df <- data.frame(means)
ggplot(df,aes(x = means)) +
geom_histogram(aes(y=..density..), bins=50, colour="black",fill="blue") +
labs(title="Exponential distribution", y="Density %") +
stat_function(fun=dnorm,args=list( mean=1/lambda, sd=sqrt(theoretical_variance)), color = "red", size = 1.0) +
stat_function(fun=dnorm,args=list( mean=mean(means), sd=sqrt(variance)), color = "green", size = 1.0)
qqnorm(means, main ="Q-Q Plot")
qqline(means, col = "3")
library(ggplot2)
library(datasets)
data(ToothGrowth)
rm(list = ls())     # clear objects
graphics.off()      # close graphics windows
library(ggplot2)
library(datasets)
data(ToothGrowth)
dim(ToothGrowth)
summary(ToothGrowth)
head(ToothGrowth)
str(ToothGrowth)
str(ToothGrowth)
sum(is.na(ToothGrowth))
ggplot(ToothGrowth, aes(x=factor(dose), y=len, fill=factor(dose))) +
geom_boxplot() +
facet_grid(.~supp) +
xlab("Dosage") +
ylab("Teeth Growth") +
ggtitle("Teeth Growth by supplement type")
boxplot(len ~ supp * dose, data=ToothGrowth, col="green",
ylab="Tooth Length", main="Boxplots of Tooth Growth Data")
head(data)
summary(data)
head(ToothGrowth)
summary(ToothGrowth)
dose<-as.factor(ToothGrowth$dose)
table(data$supp, ToothGrowth$dose)
summary(ToothGrowth)
dose<-as.factor(ToothGrowth$dose)
table(data$supp, ToothGrowth$dose)
summary(ToothGrowth)
dose<-as.factor(ToothGrowth$dose)
table(ToothGrowth$supp, ToothGrowth$dose)
dose<-as.factor(ToothGrowth$dose)
table(ToothGrowth$supp, ToothGrowth$dose)
summary(ToothGrowth)
dose<-as.factor(ToothGrowth$dose)
table(ToothGrowth$supp, ToothGrowth$dose)
# T Test by supplemant type
t.test(len ~ supp, data = ToothGrowth)
# T test by dose level
Tooth.dose0.5_1.0 <- subset(ToothGrowth, dose %in% c(0.5, 1.0))
Tooth.dose0.5_2.0 <- subset(ToothGrowth, dose %in% c(0.5, 2.0))
Tooth.dose1.0_2.0 <- subset(ToothGrowth, dose %in% c(1.0, 2.0))
t.test(len ~ dose, data = Tooth.dose0.5_1.0)
t.test(len ~ dose, data = Tooth.dose0.5_2.0)
t.test(len ~ dose, data = Tooth.dose1.0_2.0)
# T test for supplement by dose level
Tooth.dose0.5 <- subset(ToothGrowth, dose == 0.5)
Tooth.dose1.0 <- subset(ToothGrowth, dose == 1.0)
Tooth.dose2.0 <- subset(ToothGrowth, dose == 2.0)
t.test(len ~ supp, data = Tooth.dose0.5)
t.test(len ~ supp, data = Tooth.dose1.0)
t.test(len ~ supp, data = Tooth.dose2.0)
qplot(dose,len, data = ToothGrowth, facets = .~supp)+ geom_smooth()+ylab("Tooth Length")+ xlab("Dosage in Milligrams/Day")
boxplot(len ~ supp * dose, data=ToothGrowth, col="green",
ylab="Tooth Length", main="Boxplots of Tooth Growth")
DoseSupSplit<-split(ToothGrowth, list(ToothGrowth$supp, ToothGrowth$dose))
MnD_SupSplt<-sapply(DoseSupSplit, function(x) mean( x[,"len"], na.rm = TRUE))
print( "Means"); MnD_SupSplt
SdD_SupSplt<-sapply(DoseSupSplit, function(x) sd( x[,"len"], na.rm = TRUE))
print("Standard Deviations"); SdD_SupSplt
oj<-ToothGrowth[ToothGrowth$supp %in% c("OJ"),]
vc<-ToothGrowth[ToothGrowth$supp %in% c("VC"),]
ojdose5<-subset(oj, oj$dose == 0.5)
ojdose1<-subset(oj, oj$dose == 1)
ojdose2<-subset(oj, oj$dose == 2)
vcdose5<-subset(vc, vc$dose == 0.5)
vcdose1<-subset(vc, vc$dose == 1)
vcdose2<-subset(vc, vc$dose == 2)
print("0.5 MG Dosage")
t.test(ojdose5$len, vcdose5$len, paired = FALSE)
print("0.5 MG Dosage")
t.test(ojdose5$len, vcdose5$len, paired = FALSE)
print("1.0 MG Dosage")
t.test(ojdose1$len, vcdose1$len, paired = FALSE)
print("2.0 MG dosage")
t.test(ojdose2$len, vcdose2$len, paired = FALSE)
print("0.5 MG Dosage")
t.test(ojdose05$len, vcdose5$len, paired = FALSE)
oj<-ToothGrowth[ToothGrowth$supp %in% c("OJ"),]
vc<-ToothGrowth[ToothGrowth$supp %in% c("VC"),]
ojdose05<-subset(oj, oj$dose == 0.5)
ojdose1<-subset(oj, oj$dose == 1)
ojdose2<-subset(oj, oj$dose == 2)
vcdose05<-subset(vc, vc$dose == 0.5)
vcdose1<-subset(vc, vc$dose == 1)
vcdose2<-subset(vc, vc$dose == 2)
print("0.5 MG Dosage")
t.test(ojdose05$len, vcdose05$len, paired = FALSE)
print("1.0 MG Dosage")
t.test(ojdose1$len, vcdose1$len, paired = FALSE)
print("2.0 MG dosage")
t.test(ojdose2$len, vcdose2$len, paired = FALSE)
t.test(len ~ supp, paired = F, var.equal = F, data = ToothGrowth)
t.test(len ~ supp, paired = F, var.equal = F, data = ToothGrowth)
?ToothGrowth
knitr::opts_chunk$set(echo = TRUE)
library(car)
library(car)
library(mtcars_)
library(mtcars)
library(mtcar)
mtcars
data(mtcars)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(ggplot2)
data(mtcars)
name(mtcars)
names(mtcars)
summary(cars)
library(dplyr)
library(ggplot2)
data(mtcars)
names(mtcars)
summary(cars)
?mtcars
mtcars$am <- as.factor(mtcars$am)
levels(mtcars$am) <-c("Automatic", "Manual")
mtcars$am <- as.factor(mtcars$am)
levels(mtcars$am) <-c("Automatic", "Manual")
t.test(mtcars$mpg~mtcars$am,conf.level=0.95)
vif(lm(mpg~., mtcars))
library(dplyr)
library(ggplot2)
library(gridExtra)
install.packages("car")
library(dplyr)
library(ggplot2)
library(car)
data(mtcars)
names(mtcars)
summary(cars)
mtcars$am <- as.factor(mtcars$am)
levels(mtcars$am) <-c("Automatic", "Manual")
t.test(mtcars$mpg~mtcars$am,conf.level=0.95)
vif(lm(mpg~., mtcars))
best <- step(lm(mpg ~ ., mtcars),trace=0)
best$coefficients
best <- step(lm(mpg ~ ., mtcars),trace=0)
best$coefficients
summary(best)
vif(best)
a <- t.test(mtcars$mpg~mtcars$am,conf.level=0.95)
diff <- a$estimate[2] - a$estimate[1]
diff
a$p.value
a <- t.test(mtcars$mpg~mtcars$am,conf.level=0.95)
diff <- a$estimate[2] - a$estimate[1]
a$p.value
a <- t.test(mtcars$mpg~mtcars$am,conf.level=0.95)
diff <- a$estimate[2] - a$estimate[1]
diff
a$p.value
newfit <- lm(mpg ~ wt + qsec + am*wt, data=MtCars)
newfit <- lm(mpg ~ wt + qsec + am*wt, data=mtcars)
anova(best, newfit)
firstfit <- lm(mpg ~ am, data=mtcars)
newfit <- lm(mpg ~ wt + qsec + am*wt, data=mtcars)
anova(firstfit, best, newfit)
firstfit <- lm(mpg ~ am, data=mtcars)
newfit <- lm(mpg ~ wt + qsec + am*wt, data=mtcars)
anova(firstfit, best, newfit)
summary(newfit)
firstfit <- lm(mpg ~ am, data=mtcars)
newfit <- lm(mpg ~ wt + qsec + am*wt, data=mtcars)
anova(firstfit, best, newfit)
summary(newfit)
g1 <- ggplot(data = mtcars, aes(x = am, y = mpg)) + geom_boxplot()
g2 <- ggplot(data = mtcars, aes(x = am, y = wt)) + geom_boxplot()
g3 <- ggplot(data = mtcars, aes(x = am, y = qsec)) + geom_boxplot()
g1
g2
g3
summary(firstfit)
summary(best)
summary
par(mfrow = c(2,2))
plot(improvedFit)
par(mfrow = c(2,2))
plot(newfit)
---
title: "MPG for automatic and manual transmissions"
author: "Peng"
date: "November 5, 2017"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Instructions
This analysis tries to find the relationship between MPG(Miles per gallons) and transmission(Automatic/Manual) of the car in the dataset `mtcars`(default available in R).
Answer the following two questions:
Determine whether automatic or manual transmission better for MPG.
Quantify the MPG difference between automatic and manual transmissions.
# Processing Data
First we load the data and library:
```{r message=FALSE}
library(dplyr)
library(ggplot2)
library(car)
data(mtcars)
names(mtcars)
```
```{r}
summary(cars)
```
With `?mtcars` we can find that `am` is the transmission type and `0 = automatic, 1 = manual`. Then we change the `am` variable to factor for better view in plots.
```{r}
mtcars$am <- as.factor(mtcars$am)
levels(mtcars$am) <-c("Automatic", "Manual")
```
We can t-test a statistical analysis, see appendix (1)
In the appendix (2), we can see the relationship between `mpg` and `am`. At first glance manual car has better mpg compared with automatic cars.
Since the p-value is 0.001374, we may reject the null hypothesis and conclude that automatic transmission cars have lower mpg compared with manual transmission cars, while based on other characteristics of automatic and manual transmission cars are the same.
Let's take a look at the pairwise plots of all the variables, many of which may not be independent.
```{r}
vif(lm(mpg~., mtcars))
```
Using the step() function, we are trying to get a better fit model.
```{r}
best <- step(lm(mpg ~ ., mtcars),trace=0)
best$coefficients
```
library(dplyr)
library(ggplot2)
library(car)
data(mtcars)
names(mtcars)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(car)
data(mtcars)
names(mtcars)
knitr::opts_chunk$set(echo = TRUE)
loadData <- function(link) {
data <- read.csv(link)
data <- data[, -c(1:7)]
}
training <- loadData('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv')
testing  <- loadData('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv')
table(training$classe)
validCol <- colSums(is.na(training)) == 0 & colSums(is.na(testing)) == 0
testing  <- testing[, validCol]
training <- training[, validCol]
library(caret)
set.seed(12345)
inTrain <- createDataPartition(training$classe, p=0.75, list=FALSE)
subtraining <- training[inTrain,]
crossvalid <- training[-inTrain,]
library(rpart)
library(rpart.plot)
install.packages('rpart')
install.packages("rpart")
knitr::opts_chunk$set(echo = TRUE)
library(rpart)
library(rpart.plot)
install.packages('rpart.plot')
# Decision Tree
confusionMatrix(crossvalid$classe, predict(model_1, crossvalid, type="class"))
knitr::opts_chunk$set(echo = TRUE)
loadData <- function(link) {
data <- read.csv(link)
data <- data[, -c(1:7)]
}
training <- loadData('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv')
testing  <- loadData('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv')
table(training$classe)
validCol <- colSums(is.na(training)) == 0 & colSums(is.na(testing)) == 0
testing  <- testing[, validCol]
training <- training[, validCol]
library(caret)
set.seed(12345)
inTrain <- createDataPartition(training$classe, p=0.75, list=FALSE)
subtraining <- training[inTrain,]
crossvalid <- training[-inTrain,]
library(rpart)
library(rpart.plot)
model_1 <- rpart(classe ~ ., data=subtraining, method="class")
library(randomForest)
install.packages('randomForest')
library(randomForest)
model_2 <- randomForest(classe ~ ., data=subtraining)
# Decision Tree
confusionMatrix(crossvalid$classe, predict(model_1, crossvalid, type="class"))
install.packages('e1071')
# Decision Tree
confusionMatrix(crossvalid$classe, predict(model_1, crossvalid, type="class"))
# Random Forest
confusionMatrix(crossvalid$classe, predict(model_2, crossvalid))
predict(model_2, testing)
rpart.plot(model_1, main="Classification Tree", extra = 102)
knitr::opts_chunk$set(echo = TRUE)
training <- read.csv('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv')
training <- training[, -c(1:7)]
testing  <- read.csv('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv')
testing <- testing[, -c(1:7)]
table(training$classe)
Col <- colSums(is.na(training)) == 0 & colSums(is.na(testing)) == 0
testing  <- testing[, Col]
training <- training[, Col]
library(caret)
set.seed(10000)
inTrain <- createDataPartition(training$classe, p=0.75, list=FALSE)
subtraining <- training[inTrain,]
crossvalid <- training[-inTrain,]
library(rpart)
library(rpart.plot)
modelA <- rpart(classe ~ ., data=subtraining, method="class")
library(randomForest)
modelB <- randomForest(classe ~ ., data=subtraining)
# Decision Tree
confusionMatrix(crossvalid$classe, predict(modelA, crossvalid, type="class"))
# Random Forest
confusionMatrix(crossvalid$classe, predict(modelB, crossvalid))
predict(modelB, testing)
table(training$classe)
Col <- colSums(is.na(training)) == 0 & colSums(is.na(testing)) == 0
testing  <- testing[, Col]
training <- training[, Col]
library(caret)
set.seed(10000)
inTrain <- createDataPartition(training$classe, p=0.75, list=FALSE)
subtraining <- training[inTrain,]
crossvalid <- training[-inTrain,]
library(rpart)
library(rpart.plot)
modelA <- rpart(classe ~ ., data=subtraining, method="class")
library(randomForest)
modelB <- randomForest(classe ~ ., data=subtraining)
# Decision Tree
confusionMatrix(crossvalid$classe, predict(modelA, crossvalid, type="class"))
# Random Forest
confusionMatrix(crossvalid$classe, predict(modelB, crossvalid))
predict(modelB, testing)
install.packages("shiny")
shiny::runApp('C:/Peng/shinyapp/myapp')
runApp('C:/Peng/shinyapp/myapp')
runApp('C:/Peng/shinyapp/myapp')
mtcars
mtcars$am
runApp('C:/Peng/shinyapp/myapp')
runApp('C:/Peng/shinyapp/myapp')
runApp('C:/Peng/shinyapp/myapp')
mtcars$am[1]
runApp('C:/Peng/shinyapp/myapp')
runApp('C:/Peng/shinyapp/myapp')
runApp('C:/Peng/shinyapp/myapp')
mtcars$hp
mean(mtcars$hp)
mean(mtcars$wt)
runApp('C:/Peng/shinyapp/myapp')
runApp('C:/Peng/shinyapp/myapp')
runApp('C:/Peng/shinyapp/myapp')
runApp('C:/Peng/shinyapp/myapp')
install.packages('rsconnect')
install.packages('rsconnect')
install.packages("rsconnect")
shiny::runApp('C:/Peng/Shiny-Application-and-Reproducible-Pitch')
rsconnect::setAccountInfo(name='pzeng123',
token='3F783E8B56B004F8E7A466B94D123BA1',
secret='<SECRET>')
rsconnect::setAccountInfo(name='pzeng123',
token='3F783E8B56B004F8E7A466B94D123BA1',
secret='1c3/FOvb2NOi1HF20Ve81eFAViLaAPxeYyG5WTfp')
setwd("C:/Peng/Shiny-Application-and-Reproducible-Pitch")
library(rsconnect)
deployApp()
rsconnect::deployApp("C:/Peng/Shiny-Application-and-Reproducible-Pitch")
setwd("~/")
setwd()
setwd("~/")
runApp('C:/Peng/Shiny-Application-and-Reproducible-Pitch')
getwd()
setwd("~/")
getwd()
setwd(/)
setwd(./)
runApp()
runApp()
setwd("C:/Peng/Shiny-Application-and-Reproducible-Pitch")
runApp()
